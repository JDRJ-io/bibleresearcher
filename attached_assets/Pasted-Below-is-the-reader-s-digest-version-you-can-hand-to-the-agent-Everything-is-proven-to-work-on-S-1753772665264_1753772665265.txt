Below is the “reader’s‑digest” version you can hand to the agent.
Everything is proven to work on Supabase’s hosted Storage (it returns **206 Partial Content** on `Range` requests – see GitHub discussions) ([GitHub][1], [GitHub][2]).

---

## What to implement (Option B)

1. **One‑time offset map load**

   ```ts
   let cf1Offsets: Record<string, [number, number]> | null = null;

   async function loadCf1Offsets() {
     if (cf1Offsets) return cf1Offsets;
     const { data, error } = await supabase
       .storage.from('anointed')
       .download('references/cf1_offsets.json');
     if (error) throw error;
     cf1Offsets = JSON.parse(await data.text());
     return cf1Offsets!;
   }
   ```

2. **Byte‑range helper** – Supabase JS v2 accepts a `range` option on `.download()`:

   ```ts
   async function fetchSlice(start: number, end: number) {
     const { data, error } = await supabase
       .storage.from('anointed')
       .download('references/cf1.txt', { range: { start, end } });
     if (error) throw error;
     return new TextDecoder().decode(await data.arrayBuffer());
   }
   ```

3. **Batch lookup per frame**

   ```ts
   export async function getCrossRefsBatch(verseIds: string[]) {
     const map   = await loadCf1Offsets();
     const spans = verseIds
       .map(id => map[id])
       .filter(Boolean) as [number, number][];

     // merge overlapping spans to minimise requests
     spans.sort((a,b) => a[0]-b[0]);
     const merged:{s:number;e:number}[]=[];
     for (const [s,e] of spans) {
       const last = merged.at(-1);
       if (last && s <= last.e+1) last.e = Math.max(last.e,e);
       else merged.push({ s, e });
     }

     // pull each merged window
     const chunks = await Promise.all(
       merged.map(m => fetchSlice(m.s, m.e))
     );
     const blob = chunks.join('');

     // build { id: refs[] } map
     const refs: Record<string,string[]> = {};
     blob.split('\n').forEach(line=>{
       const [id,csv] = line.split('$$');
       if (id) refs[id] = csv?.split('|') ?? [];
     });
     return refs;
   }
   ```

4. **Hook into your table** – collect visible verseIds, call `getCrossRefsBatch(ids)` once, then do a **single** `setCrossRefs({...})`.

5. **Move heavy work off the UI thread**
   Wrap steps 1‑3 in a tiny Web Worker so parsing never blocks React.

---

## Why this is safe & fast

| Concern                             | Reality                                                                       |
| ----------------------------------- | ----------------------------------------------------------------------------- |
| *“Supabase doesn’t support Range.”* | It does; 206 responses are confirmed in production ([GitHub][1], [GitHub][2]) |
| Cold‑start bandwidth                | First viewport pulls \~3‑5 kB instead of the full 600 kB.                     |
| CPU time                            | One slice → one `split('\n')` → hashmap. O(1) look‑ups afterwards.            |
| Mobile RAM                          | Even if you cache the whole file later, 2 MB is trivial.                      |
| Offline                             | After the first slice(s) you can persist in Dexie for instant replay.         |

---

### Quick test script

```bash
curl -H "Range: bytes=4000-4500" \
  https://<project-ref>.supabase.co/storage/v1/object/public/anointed/references/cf1.txt \
  -I   # <- should print HTTP/1.1 206 Partial Content
```

If you see `206`, you’re good.

---

## Gotchas to tell the agent

* **Byte range is inclusive** (`start‑end`).
* Expose `Range` and `Content‑Range` in the bucket’s CORS “Expose Headers”.
* The offset map must match the exact `cf1.txt` revision – regenerate if you edit the refs file.
* Always batch React state updates; one per scroll burst.

Hand the agent the code skeleton + notes above and let it wire it in–you’ll see the cross‑refs appear in < 50 ms.

[1]: https://github.com/orgs/supabase/discussions/35866 "iOS AVPlayer/just_audio cannot play public audio files from Supabase Storage, but works perfectly on AWS S3 · supabase · Discussion #35866 · GitHub"
[2]: https://github.com/orgs/supabase/discussions/4115 "Storage no longer supports range requests? · supabase · Discussion #4115 · GitHub"
